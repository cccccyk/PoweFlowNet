import os
import logging
import torch
import numpy as np
from torch_geometric.loader import DataLoader
from sklearn.metrics import confusion_matrix, classification_report # [æ–°å¢] ç”¨äºå®‰å…¨è¯„ä¼°ç»Ÿè®¡

# å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å—
from datasets.PowerFlowData import PowerFlowData 
from networks.MPN import MaskEmbdMultiMPN_GPS
from utils.evaluation import load_model
from utils.argument_parser import argument_parser

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==========================================
# 1. ç‰©ç†è¾…åŠ©å‡½æ•°
# ==========================================

def rect_to_polar(e, f):
    """å°†ç›´è§’åæ ‡é¢„æµ‹å€¼è½¬æ¢ä¸ºæåæ ‡ (Vm, Va_degree)"""
    vm = torch.sqrt(e**2 + f**2 + 1e-12)
    va_rad = torch.atan2(f, e)
    va_deg = va_rad * (180.0 / torch.pi)
    return vm, va_deg

def compute_branch_flows(e, f, edge_index, edge_attr, baseMVA=100.0):
    """
    æ ¹æ®èŠ‚ç‚¹ç”µå‹å’Œ Ybus è¾¹ç‰¹å¾è®¡ç®—æ”¯è·¯æ½®æµ (P_ij, Q_ij)
    """
    e_i, f_i = e[edge_index[0]], f[edge_index[0]]
    e_j, f_j = e[edge_index[1]], f[edge_index[1]]

    g_line = -edge_attr[:, 0]
    b_line = -edge_attr[:, 1]

    de = e_i - e_j
    df = f_i - f_j

    i_real = g_line * de - b_line * df
    i_imag = g_line * df + b_line * de

    p_ij = (e_i * i_real + f_i * i_imag) * baseMVA
    q_ij = (f_i * i_real - e_i * i_imag) * baseMVA
    
    return p_ij, q_ij

# ==========================================
# 2. æ ¸å¿ƒè¯„ä¼°å‡½æ•° (é›†æˆå®‰å…¨è¯„ä¼°)
# ==========================================

@torch.no_grad()
def evaluate_full_metrics(model, loader, device, xymean, xystd, edgemean, edgestd):
    model.eval()
    
    metrics = {
        'num_samples': 0,
        'mae_vm': 0., 'mae_va': 0.,
        'max_err_vm': 0., 'max_err_va': 0.,
        'mae_e': 0., 'mae_f': 0.,
        'branch_p_mae': 0., 'branch_p_max': 0.,
        # [æ–°å¢] å®‰å…¨è¯„ä¼°ç›¸å…³
        'all_gt_labels': [],
        'all_pred_labels': []
    }
    
    ef_mean = xymean[:, 2:4].to(device)
    ef_std  = xystd[:, 2:4].to(device)
    edgemean = edgemean.to(device)
    edgestd = edgestd.to(device)

    for data in loader:
        data = data.to(device)
        out = model(data) # é¢„æµ‹ e, f
        
        # 1. åå½’ä¸€åŒ–
        target_ef = data.y[:, 2:4]
        pred_real = out * (ef_std + 1e-7) + ef_mean
        target_real = target_ef * (ef_std + 1e-7) + ef_mean
        
        # 2. è®¡ç®—èŠ‚ç‚¹ Vm, Va
        pred_vm, pred_va = rect_to_polar(pred_real[:, 0], pred_real[:, 1])
        pred_vm = pred_vm - 0.002
        true_vm, true_va = rect_to_polar(target_real[:, 0], target_real[:, 1])
        
        # 3. æ”¯è·¯æ½®æµè®¡ç®—
        real_edge_attr = data.edge_attr * (edgestd + 1e-7) + edgemean
        p_pred, q_pred = compute_branch_flows(pred_real[:,0], pred_real[:,1], data.edge_index, real_edge_attr)
        p_true, q_true = compute_branch_flows(target_real[:,0], target_real[:,1], data.edge_index, real_edge_attr)
        
        # ==========================================
        # [æ ¸å¿ƒæ–°å¢] å®‰å…¨è¯„ä¼°åˆ¤å®šé€»è¾‘ (Security Assessment)
        # ==========================================
        # åˆ¤å®šæ ‡å‡†ï¼šç”µå‹ < 0.95 æˆ– > 1.05 ä¸ºä¸å®‰å…¨
        # æ³¨æ„ï¼šæ­¤å¤„åªæ¼”ç¤ºç”µå‹åˆ¤å®šã€‚å¦‚æœ‰çº¿è·¯é™å€¼ï¼Œä¹Ÿå¯åŠ å…¥ s_pred > s_limit çš„åˆ¤å®šã€‚
        v_unsafe_node = (pred_vm < 0.95) | (pred_vm > 1.05)
        
        fn_labels = []
        for i in range(data.num_graphs):
            # A. æå–è¯¥æ ·æœ¬çš„ Ground Truth (äºŒåˆ†ç±»ï¼šå®‰å…¨ 0 vs ä¸å®‰å…¨ 1)
            gt_status = 1 if data.label[i].item() > 0 else 0
            metrics['all_gt_labels'].append(gt_status)
            
            # B. æå– AI çš„åˆ¤å®šç»“æœ
            node_mask = (data.batch == i)
            # å¦‚æœè¯¥æ ·æœ¬ä¸­ä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹ç”µå‹è¶Šé™ï¼Œåˆ™åˆ¤å®šä¸ºä¸å®‰å…¨
            ai_v_unsafe = v_unsafe_node[node_mask].any().item()
            
            # TODO: å¦‚æœä½ æœ‰æ”¯è·¯é™å€¼ï¼Œå¯ä»¥åœ¨æ­¤åŠ å…¥æ”¯è·¯è¿‡è½½åˆ¤å®š
            # ai_p_overload = (p_pred[edge_mask].abs() > limit).any().item()
            
            pred_status = 1 if ai_v_unsafe else 0
            metrics['all_pred_labels'].append(pred_status)

            if gt_status == 1 and pred_status == 0:
                # è®°å½•æ¼æŠ¥æ ·æœ¬çš„åŸå§‹ Label (1:V, 2:P, 3:Both)
                fn_labels.append(data.label[i].item())
        # è¿è¡Œç»“æŸåæ‰“å°
        from collections import Counter
        print(f"æ¼æŠ¥æ ·æœ¬åŸå§‹ç±»å‹åˆ†å¸ƒ: {Counter(fn_labels)}")

        # 4. åŸºç¡€è¯¯å·®ç»Ÿè®¡ (åŸæœ‰é€»è¾‘)
        node_mask_all = data.pred_mask[:, 2] # é¢„æµ‹æ©ç 
        m_sum = node_mask_all.sum().item() + 1e-6
        batch_size = data.num_graphs
        
        metrics['mae_vm'] += ((pred_vm - true_vm).abs() * node_mask_all).sum().item() / m_sum * batch_size
        metrics['mae_va'] += ((pred_va - true_va).abs() * node_mask_all).sum().item() / m_sum * batch_size
        metrics['branch_p_mae'] += (p_pred - p_true).abs().mean().item() * batch_size
        metrics['branch_p_max'] = max(metrics['branch_p_max'], (p_pred - p_true).abs().max().item())
        metrics['num_samples'] += batch_size

    # å¹³å‡åŒ–åŸºç¡€æŒ‡æ ‡
    n = metrics['num_samples']
    for k in ['mae_vm', 'mae_va', 'mae_e', 'mae_f', 'branch_p_mae']:
        metrics[k] /= n
            
    return metrics

# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================

def main():
    run_id = '20251223-6480' # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹ ID
    args = argument_parser()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. åŠ è½½å‚æ•°ä¸æ•°æ®
    data_param_path = os.path.join(args.data_dir, 'params', f'data_params_{run_id}.pt')
    data_param = torch.load(data_param_path, map_location='cpu')
    
    # æ³¨æ„ï¼šæ­¤å¤„ PowerFlowData å¿…é¡»æ˜¯ä¿®æ”¹è¿‡ã€æ”¯æŒ label çš„ç‰ˆæœ¬
    testset = PowerFlowData(root=args.data_dir, case=args.case,
                            split=[.5, .2, .3], task='test',
                            xymean=data_param['xymean'], xystd=data_param['xystd'],
                            edgemean=data_param['edgemean'], edgestd=data_param['edgestd'])
    loader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)
    
    # 2. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    node_in, _, edge_dim = testset.get_data_dimensions()
    model = MaskEmbdMultiMPN_GPS(nfeature_dim=node_in, efeature_dim=edge_dim, output_dim=2, 
                                 hidden_dim=args.hidden_dim, n_gnn_layers=args.n_gnn_layers).to(device)
    
    model, _ = load_model(model, run_id, device)
    
    # 3. è¿è¡Œè¯„ä¼°
    res = evaluate_full_metrics(model, loader, device, 
                                data_param['xymean'], data_param['xystd'],
                                data_param['edgemean'], data_param['edgestd'])
    
    # 4. è¾“å‡ºå¸¸è§„æŒ‡æ ‡
    print("\n" + "="*50)
    print(f"ğŸ“Š åŸºç¡€è¯¯å·®è¯„ä¼°: {args.case}")
    print(f"  MAE Vm : {res['mae_vm']:.6f} p.u. | MAE Va : {res['mae_va']:.4f} deg")
    print(f"  P MAE  : {res['branch_p_mae']:.4f} MW   | P MAX Err: {res['branch_p_max']:.4f} MW")
    
    # ==========================================
    # 5. [æ–°å¢] å®‰å…¨è¯„ä¼°æŠ¥å‘Š (Security Report)
    # ==========================================
    gt = np.array(res['all_gt_labels'])
    pred = np.array(res['all_pred_labels'])
    
    cm = confusion_matrix(gt, pred)
    # å¤„ç†å…¨å®‰å…¨æˆ–å…¨ä¸å®‰å…¨çš„ç‰¹æ®Šæƒ…å†µï¼Œé˜²æ­¢ç´¢å¼•é”™è¯¯
    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (cm[0,0], 0, 0, 0)

    print("\n" + "="*50)
    print(f"ğŸ›¡ï¸  N-1 å®‰å…¨åˆ¤å®šè¯„ä¼° (äºŒåˆ†ç±»)")
    print("="*50)
    print(f"  å‡†ç¡®è¯†åˆ«å®‰å…¨ (TN): {tn:4d} | è¯¯æŠ¥ (FP): {fp:4d}")
    print(f"  æ¼æŠ¥æ•…éšœ (FN)  : {fn:4d} | æ­£ç¡®è¯†åˆ«æ•…éšœ (TP): {tp:4d}  <-- é‡ç‚¹å…³æ³¨!")
    
    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-9)
    recall = tp / (tp + fn + 1e-9)   # å¬å›ç‡ï¼šæ‰€æœ‰çœŸæ­£çš„æ•…éšœä¸­æœ‰å¤šå°‘è¢«AIå‘ç°äº†
    precision = tp / (tp + fp + 1e-9) # ç²¾ç¡®ç‡ï¼šAIæŠ¥å‡ºçš„æ•…éšœä¸­æœ‰å¤šå°‘æ˜¯çœŸçš„
    fnr = fn / (tp + fn + 1e-9)      # æ¼æŠ¥ç‡

    print(f"-"*50)
    print(f"  æ€»å‡†ç¡®ç‡ (Accuracy) : {accuracy:.2%}")
    print(f"  æ•…éšœæ•æ‰ç‡ (Recall)   : {recall:.2%}")
    print(f"  æ¼æŠ¥ç‡ (Miss Rate/FNR): {fnr:.2%}  (è¶Šä½è¶Šå®‰å…¨)")
    print(f"  è¯¯æŠ¥ç‡ (Fall-out/FPR) : {fp/(fp+tn+1e-9):.2%} (è¶Šä½è¶Šç»æµ)")
    print("="*50)

if __name__ == "__main__":
    main()