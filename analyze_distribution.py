import os
import argparse
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from torch_geometric.loader import DataLoader

# å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å—
from datasets.PowerFlowData import PowerFlowData 
from networks.MPN import MaskEmbdMultiMPN_GPS
from utils.evaluation import load_model

# ==========================================
# 1. æ ¸å¿ƒè¯Šæ–­é€»è¾‘
# ==========================================

@torch.no_grad()
def run_diagnostic(run_id, data_dir, case_name, hidden_dim, n_layers, batch_size, device):
    # --- A. åŠ è½½å½’ä¸€åŒ–å‚æ•° ---
    param_path = os.path.join(data_dir, 'params', f'data_params_{run_id}.pt')
    if not os.path.exists(param_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å‚æ•°æ–‡ä»¶: {param_path}")
    
    params = torch.load(param_path, map_location='cpu')
    xymean = params['xymean'] # [1, 6] -> [P, Q, e, f, Gii, Bii]
    xystd = params['xystd']
    
    # æå– e, f çš„åå½’ä¸€åŒ–å‚æ•°
    ef_mean = xymean[:, 2:4].to(device)
    ef_std = xystd[:, 2:4].to(device)

    # --- B. åŠ è½½æ•°æ® ---
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•é›†: {case_name}...")
    testset = PowerFlowData(
        root=data_dir, case=case_name, split=[.5, .2, .3], task='test',
        xymean=xymean, xystd=xystd,
        edgemean=params['edgemean'], edgestd=params['edgestd']
    )
    loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

    # --- C. æ„å»ºå¹¶åŠ è½½æ¨¡å‹ ---
    node_in, _, edge_dim = testset.get_data_dimensions()
    model = MaskEmbdMultiMPN_GPS(
        nfeature_dim=node_in,
        efeature_dim=edge_dim,
        output_dim=2,
        hidden_dim=hidden_dim,
        n_gnn_layers=n_layers
    ).to(device)
    
    model, _ = load_model(model, run_id, device)
    model.eval()
    print(f"âœ… æ¨¡å‹ {run_id} åŠ è½½æˆåŠŸï¼Œå¼€å§‹åˆ†æ...")

    # --- D. æå–ç”µå‹æ•°æ® ---
    all_true_vm = []
    all_pred_vm = []
    all_min_vm_true = []
    all_min_vm_pred = []
    
    for data in loader:
        data = data.to(device)
        out = model(data) # [N, 2] -> e, f
        
        # åå½’ä¸€åŒ–è¿˜åŸç‰©ç†å€¼
        pred_real = out * (ef_std + 1e-7) + ef_mean
        target_real = data.y[:, 2:4] * (ef_std + 1e-7) + ef_mean
        
        # è®¡ç®— Vm
        pred_vm = torch.sqrt(pred_real[:, 0]**2 + pred_real[:, 1]**2)
        true_vm = torch.sqrt(target_real[:, 0]**2 + target_real[:, 1]**2)
        
        # åªç»Ÿè®¡éœ€è¦é¢„æµ‹çš„èŠ‚ç‚¹ (mask)
        mask = data.pred_mask[:, 2] > 0
        all_true_vm.extend(true_vm[mask].cpu().numpy())
        all_pred_vm.extend(pred_vm[mask].cpu().numpy())
        
        # è®°å½•æ¯ä¸ªæ ·æœ¬ï¼ˆå›¾ï¼‰çš„æœ€å°ç”µå‹ï¼Œç”¨äºåˆ¤å®šå®‰å…¨æ€§
        for i in range(data.num_graphs):
            m = (data.batch == i) & mask
            if m.any():
                all_min_vm_true.append(true_vm[m].min().item())
                all_min_vm_pred.append(pred_vm[m].min().item())

    all_true_vm = np.array(all_true_vm)
    all_pred_vm = np.array(all_pred_vm)
    all_min_vm_true = np.array(all_min_vm_true)
    all_min_vm_pred = np.array(all_min_vm_pred)

    # --- E. è®¡ç®—å®šé‡ç»Ÿè®¡ ---
    errors = all_pred_vm - all_true_vm
    me = np.mean(errors) # ç³»ç»Ÿæ€§åç½®
    mae = np.mean(np.abs(errors))
    
    print("\n" + "="*50)
    print("ğŸ“Š æ•°æ®åˆ†å¸ƒè¯Šæ–­æŠ¥å‘Š")
    print("="*50)
    print(f"Mean Error (ç³»ç»Ÿæ€§åç½®): {me:.6f} p.u.")
    print(f"MAE (å¹³å‡ç»å¯¹è¯¯å·®)   : {mae:.6f} p.u.")
    print(f"ç‰©ç†å®‰å…¨é˜ˆå€¼         : 0.95 p.u.")
    
    if me < -0.001:
        print(f"ğŸ’¡ ç»“è®ºï¼šæ¨¡å‹å€¾å‘äºã€ä½ä¼°ã€‘ç”µå‹ï¼Œè¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆè¯¯æŠ¥ç‡(FP)é‚£ä¹ˆé«˜ã€‚")
    elif me > 0.001:
        print(f"ğŸ’¡ ç»“è®ºï¼šæ¨¡å‹å€¾å‘äºã€é«˜ä¼°ã€‘ç”µå‹ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¼æŠ¥(FN)ã€‚")
    else:
        print(f"ğŸ’¡ ç»“è®ºï¼šæ¨¡å‹æ— æ˜æ˜¾ç³»ç»Ÿæ€§åç½®ï¼Œè¯¯å·®ä¸»è¦æ¥è‡ªéšæœºæ‰°åŠ¨ã€‚")
    
    # è®¡ç®—ä¸´ç•ŒåŒºæ ·æœ¬æ¯”ä¾‹
    border_samples = np.sum((all_min_vm_true > 0.94) & (all_min_vm_true < 0.96))
    print(f"è¾¹ç•ŒåŒºæ ·æœ¬æ•° (0.94~0.96): {border_samples} ({border_samples/len(all_min_vm_true):.1%} of total)")
    print("="*50)

    # --- F. ç»˜å›¾å¯è§†åŒ– ---
    plt.figure(figsize=(20, 6))
    sns.set_theme(style="whitegrid")

    # 1. å…¨ç½‘èŠ‚ç‚¹ç”µå‹åˆ†å¸ƒå›¾
    plt.subplot(1, 3, 1)
    sns.kdeplot(all_true_vm, color="blue", label="True Vm", fill=True, alpha=0.3)
    sns.kdeplot(all_pred_vm, color="red", label="Pred Vm", fill=True, alpha=0.3)
    plt.axvline(0.95, color='green', linestyle='--', label='Safety Limit (0.95)')
    plt.title("All Nodes Voltage Density", fontsize=14)
    plt.xlabel("Voltage (p.u.)")
    plt.legend()

    # 2. æ¯ä¸ªæ ·æœ¬æœ€å°ç”µå‹åˆ†å¸ƒ (å†³å®šå®‰å…¨åˆ¤å®šçš„å…³é”®)
    plt.subplot(1, 3, 2)
    sns.histplot(all_min_vm_true, color="blue", label="True Min Vm", alpha=0.5, bins=50)
    sns.histplot(all_min_vm_pred, color="red", label="Pred Min Vm", alpha=0.5, bins=50)
    plt.axvline(0.95, color='black', linestyle='--', label='0.95 Limit')
    plt.title("Sample Minimum Voltage (Decision Critical)", fontsize=14)
    plt.xlabel("Min Voltage in Graph (p.u.)")
    plt.legend()

    # 3. é¢„æµ‹æ®‹å·®åˆ†å¸ƒ (Pred - True)
    plt.subplot(1, 3, 3)
    sns.histplot(errors, color="purple", kde=True, bins=100)
    plt.axvline(0, color='black', linestyle='-')
    plt.axvline(me, color='red', linestyle='--', label=f'Mean Bias: {me:.4f}')
    plt.title("Prediction Residuals (Pred - True)", fontsize=14)
    plt.xlabel("Error (p.u.)")
    plt.legend()

    plot_name = f"diagnostic_{run_id}.png"
    plt.tight_layout()
    plt.savefig(plot_name, dpi=150)
    print(f"\nâœ… è¯Šæ–­å›¾è¡¨å·²ä¿å­˜è‡³: {plot_name}")

# ==========================================
# 2. å‚æ•°è§£æä¸å…¥å£
# ==========================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--run_id', type=str, default='20251223-6480', help='è®­ç»ƒæ—¶çš„ID')
    parser.add_argument('--data_dir', type=str, default='./data', help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--case', type=str, default='118v_n1_train', help='Caseåç§°')
    parser.add_argument('--hidden_dim', type=int, default=128)
    parser.add_argument('--n_layers', type=int, default=4)
    parser.add_argument('--batch_size', type=int, default=32)
    args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    run_diagnostic(
        args.run_id, args.data_dir, args.case, 
        args.hidden_dim, args.n_layers, args.batch_size, device
    )